{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end Neural Network classification\n",
    "\n",
    "This notebooks synthesizes all the previous notebooks into a single pipeline. It is a good starting point to understand how to use the pipeline from end to end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will train a Neural Network to classify the kickstarter dataset to predict the success status of a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from beexai.dataset.dataset import Dataset\n",
    "from beexai.dataset.load_data import load_data\n",
    "from beexai.evaluate.metrics.get_results import get_all_metrics\n",
    "from beexai.explanation.explaining import CaptumExplainer\n",
    "from beexai.training.train import Trainer\n",
    "from beexai.utils.path import create_dir\n",
    "from beexai.utils.sampling import stratified_sampling\n",
    "from beexai.utils.time_seed import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will add a column `duration` which is the difference between the `deadline` and `launched` columns. We will also drop the entries with value `N,0` for the column `country` and values `live` for the column `state`.\n",
    "\n",
    "`load_data` function also allows to remove correlated features with a default threshold of 70% and one-hot encode categorical features with the possibility of making an exception for high dimensional features which would result in too many columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_NAME = \"kickstarter\"\n",
    "MODEL_NAME = \"NeuralNetwork\"\n",
    "\n",
    "create_dir(f\"../output/data\")\n",
    "CONFIG_PATH = f\"config/{DATA_NAME}.yml\"\n",
    "data_test, target_col, task, dataCleaner = load_data(\n",
    "    from_cleaned=True, config_path=CONFIG_PATH, keep_corr_features=True\n",
    ")\n",
    "scale_params = {\n",
    "    \"x_num_scaler_name\": \"quantile_normal\",\n",
    "    \"x_cat_encoder_name\": \"ordinalencoder\",\n",
    "    \"y_scaler_name\": \"labelencoder\",\n",
    "    \"cat_not_to_onehot\": [\"name\"],\n",
    "}\n",
    "data = Dataset(data_test, target_col)\n",
    "X_train, X_test, y_train, y_test = data.get_train_test(\n",
    "    test_size=0.2, scaler_params=scale_params\n",
    ")\n",
    "X_train, X_val, y_train, y_val = data.get_train_val(X_train, y_train, val_size=0.2)\n",
    "num_labels = data.get_classes_num(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of a neural network, we need to specify the input and output shape of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_PARAMS = {\"input_dim\": X_train.shape[1], \"output_dim\": num_labels}\n",
    "trainer = Trainer(MODEL_NAME, task, NN_PARAMS, device)\n",
    "trainer.train(\n",
    "    X_train.values,\n",
    "    y_train.values,\n",
    "    loss_file=f\"../output/loss.png\",\n",
    "    x_val=X_val,\n",
    "    y_val=y_val,\n",
    ")\n",
    "trainer.model.eval()\n",
    "metrics = trainer.get_metrics(X_test, y_test)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two formats are available for saving your model: `pt` and `joblib`. The `pt` format is made for PyTorch models and the `joblib` format is made for sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(f\"../output/models/{DATA_NAME}\")\n",
    "trainer.save_model(f\"../output/models/{DATA_NAME}/{MODEL_NAME}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For faster testing, we use the function `stratified_sampling` that samples a fraction of the data while keeping the same distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = stratified_sampling(X_test, y_test, 100, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captum Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many choices of explainers are available in Captum. We will use the `IntegratedGradients` explainer for this example but it is also possible to use `DeepLift`, `Lime`, `ShapleyValueSampling` and other XAI methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CaptumExplainer(\n",
    "    trainer.model, task=task, method=\"IntegratedGradients\", sklearn=False, device=device\n",
    ")\n",
    "explainer.init_explainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate IG with XAI metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several quantitative metrics are also implemented to evaluate the explanations. It is also possible to have safety checks on the explanations with the training of a model on shuffled labels and a random explainability baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = trainer.model.predict(X_test.values)\n",
    "get_all_metrics(\n",
    "    X_test,\n",
    "    all_preds,\n",
    "    trainer.model,\n",
    "    explainer,\n",
    "    baseline=\"zero\",\n",
    "    auc_metric=\"accuracy\",\n",
    "    print_plot=False,\n",
    "    save_path=None,\n",
    "    device=device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
