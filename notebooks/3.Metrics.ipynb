{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get explainability metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from beexai.dataset.dataset import Dataset\n",
    "from beexai.dataset.load_data import load_data\n",
    "from beexai.evaluate.metrics.get_results import get_all_metrics\n",
    "from beexai.explanation.explaining import CaptumExplainer\n",
    "from beexai.training.train import Trainer\n",
    "from beexai.utils.time_seed import set_seed\n",
    "from beexai.utils.sampling import stratified_sampling\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_NAME = \"kickstarter\"\n",
    "MODEL_NAME = \"NeuralNetwork\"\n",
    "CONFIG_PATH = f\"config/{DATA_NAME}.yml\"\n",
    "data_test, target_col, task, _ = load_data(from_cleaned=True, config_path=CONFIG_PATH)\n",
    "scale_params = {\n",
    "    \"x_num_scaler_name\": \"quantile_normal\",\n",
    "    \"x_cat_encoder_name\": \"ordinalencoder\",\n",
    "    \"y_scaler_name\": \"labelencoder\",  # change to minmax or another float scaler for regression\n",
    "    \"cat_not_to_onehot\": [\"name\"],\n",
    "}\n",
    "data = Dataset(data_test, target_col)\n",
    "X_train, X_test, y_train, y_test = data.get_train_test(\n",
    "    test_size=0.2, scaler_params=scale_params\n",
    ")\n",
    "NUM_LABELS = data.get_classes_num(task)\n",
    "\n",
    "NN_PARAMS = {\"input_dim\": X_train.shape[1], \"output_dim\": NUM_LABELS}\n",
    "trainer = Trainer(MODEL_NAME, task, NN_PARAMS, device)\n",
    "# trainer = Trainer(\"XGBClassifier\", task, device=device)\n",
    "trainer.load_model(f\"../output/models/{DATA_NAME}/{MODEL_NAME}.pt\")\n",
    "\n",
    "TEST_SIZE = 100\n",
    "X_test, y_test = stratified_sampling(X_test, y_test, TEST_SIZE, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dummy\n",
    "\n",
    "Train a dummy model on shuffled labels to compare with the real model explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMMY_TRAIN_SIZE = 100\n",
    "X_train_sampled, y_train_sampled = stratified_sampling(\n",
    "    X_train, y_train, DUMMY_TRAIN_SIZE, task\n",
    ")\n",
    "rand_trainer = Trainer(MODEL_NAME, task, NN_PARAMS, device)\n",
    "# rand_trainer = Trainer(\"XGBClassifier\", task, device=device)\n",
    "X_perm, y_perm = X_train_sampled.values, np.random.permutation(y_train_sampled.values)\n",
    "rand_trainer.train(X_perm, y_perm, loss_file=\"../output/loss.png\")\n",
    "rand_trainer.model.eval()  # comment if not NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metrics\n",
    "\n",
    "Initialize the explainers for the model and the dummy model. \n",
    "\n",
    "Compute the metrics for the test set.\n",
    "\n",
    "Feel free to look at the other optional arguments to select hyperparameters, display plots, select only some metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = \"IntegratedGradients\"  # change this to a Non-Gradient based method for sklearn models\n",
    "exp = CaptumExplainer(\n",
    "    trainer.model, task=task, method=METHOD, sklearn=False, device=device\n",
    ")  # change sklearn to True if not NN\n",
    "exp.init_explainer()\n",
    "attributions = exp.compute_attributions(\n",
    "    X_test,\n",
    "    DATA_NAME,\n",
    "    MODEL_NAME,\n",
    "    METHOD,\n",
    "    \"../output/explain/\",\n",
    "    use_abs=False,  # change to True for regression\n",
    ")\n",
    "\n",
    "rand_exp = CaptumExplainer(\n",
    "    rand_trainer.model, task=task, method=METHOD, sklearn=False, device=device\n",
    ")  # change sklearn to True if not NN\n",
    "rand_exp.init_explainer()\n",
    "rand_attributions = rand_exp.compute_attributions(\n",
    "    X_test, DATA_NAME, MODEL_NAME, METHOD, \"../output/explain/\", use_abs=False\n",
    ")\n",
    "\n",
    "all_preds = trainer.model.predict(\n",
    "    X_test.values\n",
    ")  # Get model predictions for metric computation\n",
    "get_all_metrics(\n",
    "    X_test,\n",
    "    all_preds,\n",
    "    trainer.model,\n",
    "    exp,\n",
    "    rand_trainer.model,\n",
    "    rand_exp,\n",
    "    print_plot=True,\n",
    "    auc_metric=\"accuracy\", #change to mse for regression\n",
    "    device=device,\n",
    "    use_random=True,\n",
    "    use_ref=True,\n",
    "    attributions=attributions,\n",
    "    attributions_ref=rand_attributions,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
